
learning time-serise for discrimnative tasks(ai distinucuhsing different categories of tasks ) has been long stand issues. 
right now has 2:
1. undireactional next-token prediction [1.1]
2. randomly masked token prediction [1.2]

Therefore the paper has a solution called BitimelyGPT(bidirectional timely generative pre-trained transformer)
shorten form is take bo;th nxt token and prev tken prediction in alternativng ttransformer layers.

preserves - data distiribution and shapes of time-seriese. 
add-on - Additionally, the full-rank forward and backward attention matrices exhibit more expressive representation capabilities. 

superior performance in predicting neurological functionality




--- Introduction ---

timne series provide valueable insidees for status and outcomes. usefull application =  achieve accurate sequenceto-vector (seq2vec) prediction tasks for centain deasess [2]
